{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9690ac72-5d95-4cbf-875a-ae0e835593c9",
   "metadata": {},
   "source": [
    "# Lesson 1: Simple ReAct Agent from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# based on https://til.simonwillison.net/llms/python-react-pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello world\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721f92a2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# Melvin S - 212222040098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 387
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "                        model=\"gpt-4o\", \n",
    "                        temperature=0,\n",
    "                        messages=self.messages)\n",
    "        return completion.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f303b1-a4d0-408c-8cc0-515ff980717f",
   "metadata": {
    "height": 557
   },
   "outputs": [],
   "source": [
    "research_prompt = \"\"\"\n",
    "You are a Research Assistant Agent that helps with information gathering and analysis.\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer.\n",
    "\n",
    "Use Thought to describe your reasoning about the research question.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "web_search:\n",
    "e.g. web_search: Python machine learning libraries\n",
    "Simulates searching the web for information on a topic\n",
    "\n",
    "summarize_text:\n",
    "e.g. summarize_text: [long text content]\n",
    "Creates a concise summary of the provided text\n",
    "\n",
    "calculate_stats:\n",
    "e.g. calculate_stats: [1, 2, 3, 4, 5]\n",
    "Calculates basic statistics (mean, median, std) for a list of numbers\n",
    "\n",
    "translate_text:\n",
    "e.g. translate_text: Hello world -> Spanish\n",
    "Translates text to another language\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What are the best Python libraries for machine learning and their key features?\n",
    "Thought: I need to search for information about Python ML libraries and then summarize the findings\n",
    "Action: web_search: best Python machine learning libraries 2024\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: Found information about scikit-learn, TensorFlow, PyTorch, etc.\n",
    "\n",
    "Then continue with your analysis...\n",
    "\n",
    "Answer: Based on my research, the top Python ML libraries are...\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf4dcb93-6298-4cfd-b3ce-61dfac7fb35f",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "import random\n",
    "\n",
    "def web_search(query):\n",
    "    search_results = {\n",
    "        \"python machine learning\": \"Found: scikit-learn (easy-to-use), TensorFlow (deep learning), PyTorch (research-friendly), XGBoost (gradient boosting)\",\n",
    "        \"data science tools\": \"Found: pandas (data manipulation), numpy (numerical computing), matplotlib (visualization), jupyter (notebooks)\",\n",
    "        \"natural language processing\": \"Found: NLTK (comprehensive), spaCy (industrial-strength), transformers (state-of-the-art), gensim (topic modeling)\",\n",
    "        \"computer vision\": \"Found: OpenCV (traditional CV), PIL/Pillow (image processing), scikit-image (image analysis)\"\n",
    "    }\n",
    "\n",
    "    for key in search_results:\n",
    "        if any(word in query.lower() for word in key.split()):\n",
    "            return search_results[key]\n",
    "    \n",
    "    return f\"Search results for '{query}': Found general information about the topic\"\n",
    "\n",
    "def summarize_text(text):\n",
    "\n",
    "    if len(text) <= 100:\n",
    "        return f\"Summary: {text}\"\n",
    "    \n",
    "    sentences = text.split('. ')\n",
    "    if len(sentences) <= 2:\n",
    "        return f\"Summary: {text[:100]}...\"\n",
    "    \n",
    "    summary = f\"{sentences[0]}. {sentences[-1]}\"\n",
    "    return f\"Summary: {summary}\"\n",
    "\n",
    "def calculate_stats(numbers_str):\n",
    "    try:\n",
    "        # Parse the string representation of numbers\n",
    "        numbers_str = numbers_str.strip('[]')\n",
    "        numbers = [float(x.strip()) for x in numbers_str.split(',')]\n",
    "        \n",
    "        mean_val = statistics.mean(numbers)\n",
    "        median_val = statistics.median(numbers)\n",
    "        \n",
    "        if len(numbers) > 1:\n",
    "            std_val = statistics.stdev(numbers)\n",
    "        else:\n",
    "            std_val = 0\n",
    "            \n",
    "        return f\"Statistics: Mean={mean_val:.2f}, Median={median_val:.2f}, Std Dev={std_val:.2f}, Count={len(numbers)}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating statistics: {e}\"\n",
    "\n",
    "def translate_text(text_and_language):\n",
    "    translations = {\n",
    "        \"spanish\": {\"hello\": \"hola\", \"world\": \"mundo\", \"good\": \"bueno\", \"morning\": \"ma√±ana\"},\n",
    "        \"french\": {\"hello\": \"bonjour\", \"world\": \"monde\", \"good\": \"bon\", \"morning\": \"matin\"},\n",
    "        \"german\": {\"hello\": \"hallo\", \"world\": \"welt\", \"good\": \"gut\", \"morning\": \"morgen\"}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        text, target_lang = text_and_language.split(' -> ')\n",
    "        text = text.strip().lower()\n",
    "        target_lang = target_lang.strip().lower()\n",
    "        \n",
    "        if target_lang in translations:\n",
    "            words = text.split()\n",
    "            translated_words = []\n",
    "            for word in words:\n",
    "                if word in translations[target_lang]:\n",
    "                    translated_words.append(translations[target_lang][word])\n",
    "                else:\n",
    "                    translated_words.append(f\"[{word}]\")  # Keep untranslated words in brackets\n",
    "            return f\"Translation to {target_lang}: {' '.join(translated_words)}\"\n",
    "        else:\n",
    "            return f\"Translation to {target_lang}: [Simulated translation of '{text}']\"\n",
    "    except:\n",
    "        return f\"Translation: [Simulated translation of the provided text]\"\n",
    "\n",
    "research_actions = {\n",
    "    \"web_search\": web_search,\n",
    "    \"summarize_text\": summarize_text, \n",
    "    \"calculate_stats\": calculate_stats,\n",
    "    \"translate_text\": translate_text\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "932883a4-c722-42bb-aec0-b4f41c5c81a4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "def research_query(question, max_turns=7):\n",
    "    i = 0\n",
    "    research_bot = Agent(research_prompt)\n",
    "    next_prompt = question\n",
    "    \n",
    "    print(f\" Research Assistant starting investigation: {question}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        print(f\"\\n Turn {i}:\")\n",
    "        result = research_bot(next_prompt)\n",
    "        print(result)\n",
    "        \n",
    "        # Parse actions from the result\n",
    "        actions = [\n",
    "            action_re.match(a) \n",
    "            for a in result.split('\\n') \n",
    "            if action_re.match(a)\n",
    "        ]\n",
    "        \n",
    "        if actions:\n",
    "            # There is an action to run\n",
    "            action, action_input = actions[0].groups()\n",
    "            if action not in research_actions:\n",
    "                print(f\" Unknown action: {action}: {action_input}\")\n",
    "                break\n",
    "                \n",
    "            print(f\"\\nüîß Executing: {action}({action_input})\")\n",
    "            observation = research_actions[action](action_input)\n",
    "            print(f\" Observation: {observation}\")\n",
    "            next_prompt = \"Observation: {}\".format(observation)\n",
    "        else:\n",
    "            print(\"\\n Research complete!\")\n",
    "            return result\n",
    "            \n",
    "    print(f\"\\n Reached maximum turns ({max_turns})\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff362f49-dcf1-4ea1-a86c-e516e9ab897d",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                          Name : Melvin S\n",
      "                                                    Register number : 212222040098\n",
      " Research Assistant starting investigation: What are the most popular Python machine learning libraries and their main use cases?\n",
      "============================================================\n",
      "\n",
      " Turn 1:\n",
      "Thought: To answer this question, I need to search for information about the most popular Python machine learning libraries and their main use cases. This will help me identify the key libraries and what they are typically used for in the field of machine learning.\n",
      "Action: web_search: most popular Python machine learning libraries and their use cases 2024\n",
      "PAUSE\n",
      "\n",
      "üîß Executing: web_search(most popular Python machine learning libraries and their use cases 2024)\n",
      " Observation: Found: scikit-learn (easy-to-use), TensorFlow (deep learning), PyTorch (research-friendly), XGBoost (gradient boosting)\n",
      "\n",
      " Turn 2:\n",
      "Answer: Based on the information found, the most popular Python machine learning libraries and their main use cases are:\n",
      "\n",
      "1. **Scikit-learn**: Known for its ease of use, scikit-learn is widely used for traditional machine learning tasks such as classification, regression, clustering, and dimensionality reduction. It provides simple and efficient tools for data mining and data analysis.\n",
      "\n",
      "2. **TensorFlow**: Developed by Google, TensorFlow is a powerful library for deep learning applications. It is used for building and training neural networks, and is particularly popular for large-scale machine learning models and production-level deployment.\n",
      "\n",
      "3. **PyTorch**: Favored in the research community, PyTorch is known for its flexibility and ease of use in developing deep learning models. It is often used for prototyping and research due to its dynamic computation graph and intuitive interface.\n",
      "\n",
      "4. **XGBoost**: This library is specifically designed for gradient boosting, a powerful machine learning technique for regression and classification problems. XGBoost is known for its performance and speed, making it a popular choice for structured/tabular data.\n",
      "\n",
      "These libraries are widely used in the machine learning community for various tasks, each offering unique features that cater to different needs and preferences.\n",
      "\n",
      " Research complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer: Based on the information found, the most popular Python machine learning libraries and their main use cases are:\\n\\n1. **Scikit-learn**: Known for its ease of use, scikit-learn is widely used for traditional machine learning tasks such as classification, regression, clustering, and dimensionality reduction. It provides simple and efficient tools for data mining and data analysis.\\n\\n2. **TensorFlow**: Developed by Google, TensorFlow is a powerful library for deep learning applications. It is used for building and training neural networks, and is particularly popular for large-scale machine learning models and production-level deployment.\\n\\n3. **PyTorch**: Favored in the research community, PyTorch is known for its flexibility and ease of use in developing deep learning models. It is often used for prototyping and research due to its dynamic computation graph and intuitive interface.\\n\\n4. **XGBoost**: This library is specifically designed for gradient boosting, a powerful machine learning technique for regression and classification problems. XGBoost is known for its performance and speed, making it a popular choice for structured/tabular data.\\n\\nThese libraries are widely used in the machine learning community for various tasks, each offering unique features that cater to different needs and preferences.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 1: Research about machine learning libraries\n",
    "action_re = re.compile(r\"^Action:\\s*(\\w+):\\s*(.+)$\")\n",
    "print(\"                                                          Name : Melvin S\\n                                                    Register number : 212222040098\")\n",
    "ml_question = \"What are the most popular Python machine learning libraries and their main use cases?\"\n",
    "research_query(ml_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7e15a20-83d7-434c-8551-bce8dcc32be0",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                          Name : melvin S S\n",
      "                                                    Register number : 212222040098\n",
      " Research Assistant starting investigation: I have these test scores: [85, 92, 78, 96, 88, 91, 84, 89]. Can you analyze them and tell me what they mean?\n",
      "============================================================\n",
      "\n",
      " Turn 1:\n",
      "Thought: To analyze the test scores, I need to calculate basic statistics such as the mean, median, and standard deviation. This will help in understanding the distribution and central tendency of the scores.\n",
      "Action: calculate_stats: [85, 92, 78, 96, 88, 91, 84, 89]\n",
      "PAUSE\n",
      "\n",
      "üîß Executing: calculate_stats([85, 92, 78, 96, 88, 91, 84, 89])\n",
      " Observation: Statistics: Mean=87.88, Median=88.50, Std Dev=5.54, Count=8\n",
      "\n",
      " Turn 2:\n",
      "Answer: The analysis of the test scores [85, 92, 78, 96, 88, 91, 84, 89] reveals the following:\n",
      "\n",
      "- The mean (average) score is 87.88, indicating that the average performance across all tests is just under 88.\n",
      "- The median score is 88.50, which suggests that half of the scores are below 88.50 and half are above, showing a balanced distribution around the middle.\n",
      "- The standard deviation is 5.54, indicating that the scores are relatively close to the mean, with moderate variability.\n",
      "- There are a total of 8 scores in the dataset.\n",
      "\n",
      "Overall, the scores are fairly consistent with a slight spread around the average, and the performance is generally high.\n",
      "\n",
      " Research complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer: The analysis of the test scores [85, 92, 78, 96, 88, 91, 84, 89] reveals the following:\\n\\n- The mean (average) score is 87.88, indicating that the average performance across all tests is just under 88.\\n- The median score is 88.50, which suggests that half of the scores are below 88.50 and half are above, showing a balanced distribution around the middle.\\n- The standard deviation is 5.54, indicating that the scores are relatively close to the mean, with moderate variability.\\n- There are a total of 8 scores in the dataset.\\n\\nOverall, the scores are fairly consistent with a slight spread around the average, and the performance is generally high.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 2: Data analysis task\n",
    "print(\"                                                          Name : melvin S S\\n                                                    Register number : 212222040098\")\n",
    "data_question = \"I have these test scores: [85, 92, 78, 96, 88, 91, 84, 89]. Can you analyze them and tell me what they mean?\"\n",
    "research_query(data_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54ab2c74-f32e-490c-a85d-932d11444210",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                          Name : Melvin S S\n",
      "                                                    Register number : 212222040098\n",
      " Research Assistant starting investigation: Research natural language processing tools and then translate 'good morning' to Spanish\n",
      "============================================================\n",
      "\n",
      " Turn 1:\n",
      "Thought: I need to first gather information on natural language processing (NLP) tools and then translate the phrase 'good morning' to Spanish. I will start by searching for information on NLP tools.\n",
      "Action: web_search: natural language processing tools 2024\n",
      "PAUSE\n",
      "\n",
      "üîß Executing: web_search(natural language processing tools 2024)\n",
      " Observation: Found: pandas (data manipulation), numpy (numerical computing), matplotlib (visualization), jupyter (notebooks)\n",
      "\n",
      " Turn 2:\n",
      "Thought: The search results provided information on general data science tools rather than specific natural language processing tools. I need to refine my search to focus specifically on NLP tools.\n",
      "Action: web_search: top natural language processing tools 2024\n",
      "PAUSE\n",
      "\n",
      "üîß Executing: web_search(top natural language processing tools 2024)\n",
      " Observation: Found: pandas (data manipulation), numpy (numerical computing), matplotlib (visualization), jupyter (notebooks)\n",
      "\n",
      " Turn 3:\n",
      "Thought: The search results are still not providing the specific information on NLP tools that I am looking for. I will attempt another search with a more specific query to find the relevant NLP tools.\n",
      "Action: web_search: best NLP tools 2024\n",
      "PAUSE\n",
      "\n",
      "üîß Executing: web_search(best NLP tools 2024)\n",
      " Observation: Found: pandas (data manipulation), numpy (numerical computing), matplotlib (visualization), jupyter (notebooks)\n",
      "\n",
      " Turn 4:\n",
      "Thought: It seems there is an issue with retrieving the correct information on NLP tools. I will proceed with translating 'good morning' to Spanish as requested, and then I can attempt another approach to find information on NLP tools if needed.\n",
      "\n",
      "Action: translate_text: good morning -> Spanish\n",
      "PAUSE\n",
      "\n",
      "üîß Executing: translate_text(good morning -> Spanish)\n",
      " Observation: Translation to spanish: bueno ma√±ana\n",
      "\n",
      " Turn 5:\n",
      "Thought: The translation provided is incorrect. The correct translation for 'good morning' in Spanish is 'buenos d√≠as'. I will provide this correct translation and then consider how to address the issue with finding NLP tools.\n",
      "\n",
      "Answer: The correct translation of 'good morning' to Spanish is 'buenos d√≠as'. Regarding NLP tools, I encountered difficulties retrieving specific information. Common NLP tools include NLTK, spaCy, and Hugging Face's Transformers. If you need more detailed information, please let me know!\n",
      "\n",
      " Research complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Thought: The translation provided is incorrect. The correct translation for 'good morning' in Spanish is 'buenos d√≠as'. I will provide this correct translation and then consider how to address the issue with finding NLP tools.\\n\\nAnswer: The correct translation of 'good morning' to Spanish is 'buenos d√≠as'. Regarding NLP tools, I encountered difficulties retrieving specific information. Common NLP tools include NLTK, spaCy, and Hugging Face's Transformers. If you need more detailed information, please let me know!\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 3: Multi-step research with translation\n",
    "print(\"                                                          Name : Melvin S S\\n                                                    Register number : 212222040098\")\n",
    "translation_question = \"Research natural language processing tools and then translate 'good morning' to Spanish\"\n",
    "research_query(translation_question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
